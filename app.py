import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage

#.envã«è¨˜è¼‰ã•ã‚ŒãŸç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# ãƒšãƒ¼ã‚¸ã®è¨­å®š
st.set_page_config(page_title="AIå°‚é–€å®¶ãƒãƒ£ãƒƒãƒˆ", page_icon="ğŸ¤–")

# ã‚¢ãƒ—ãƒªã®æ¦‚è¦ã‚’è¡¨ç¤º
st.title("ğŸ¤– AIå°‚é–€å®¶ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒª")
st.markdown("""
### ã‚¢ãƒ—ãƒªã®æ¦‚è¦
ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€ç•°ãªã‚‹å°‚é–€åˆ†é‡ã®çŸ¥è­˜ã‚’æŒã¤AIã¨ãƒãƒ£ãƒƒãƒˆãŒã§ãã¾ã™ã€‚
è³ªå•ã—ãŸã„å†…å®¹ã«å¿œã˜ã¦ã€é©åˆ‡ãªå°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚

### æ“ä½œæ–¹æ³•
1. ä¸‹ã®ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã‹ã‚‰ç›¸è«‡ã—ãŸã„å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„
2. ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›æ¬„ã«è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„
3. ã€Œé€ä¿¡ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€AIã‹ã‚‰ã®å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™

---
""")

# å°‚é–€å®¶ã®ç¨®é¡ã¨ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å®šç¾©
EXPERT_TYPES = {
    "ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ": "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚çµŒå–¶æˆ¦ç•¥ã€ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã€äº‹æ¥­é–‹ç™ºãªã©ãƒ“ã‚¸ãƒã‚¹å…¨èˆ¬ã«é–¢ã™ã‚‹å°‚é–€çŸ¥è­˜ã‚’æŒã£ã¦ãŠã‚Šã€å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚",
    "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ": "ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®å°‚é–€å®¶ã§ã™ã€‚çµ±è¨ˆå­¦ã€æ©Ÿæ¢°å­¦ç¿’ã€ãƒ‡ãƒ¼ã‚¿åˆ†æã€ãƒ‡ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãªã©ã«ç²¾é€šã—ã¦ãŠã‚Šã€ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸæ´å¯Ÿã‚’æä¾›ã—ã¾ã™ã€‚",
    "ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢": "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã€ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãªã©ã«ç²¾é€šã—ã¦ãŠã‚Šã€æŠ€è¡“çš„ãªèª²é¡Œã«å¯¾ã™ã‚‹è§£æ±ºç­–ã‚’æä¾›ã—ã¾ã™ã€‚"
}


def get_llm_response(user_input: str, expert_type: str) -> str:
    """
    LLMã‹ã‚‰ã®å›ç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°
    
    Args:
        user_input (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        expert_type (str): é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã®ç¨®é¡
    
    Returns:
        str: LLMã‹ã‚‰ã®å›ç­”ãƒ†ã‚­ã‚¹ãƒˆ
    """
    # ChatOpenAIã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
    chat = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7)
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
    system_message = EXPERT_TYPES[expert_type]
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
    messages = [
        SystemMessage(content=system_message),
        HumanMessage(content=user_input)
    ]
    
    # LLMã«å•ã„åˆã‚ã›
    response = chat.invoke(messages)
    
    return response.content


# UIã®æ§‹ç¯‰
st.subheader("å°‚é–€å®¶ã®é¸æŠ")
expert_choice = st.radio(
    "ç›¸è«‡ã—ãŸã„å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„:",
    list(EXPERT_TYPES.keys()),
    index=0
)

st.subheader("è³ªå•ãƒ»ç›¸è«‡å†…å®¹ã®å…¥åŠ›")
user_input = st.text_area(
    "è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
    height=150,
    placeholder="ã“ã“ã«è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."
)

# é€ä¿¡ãƒœã‚¿ãƒ³
if st.button("é€ä¿¡", type="primary"):
    if user_input.strip():
        with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
            try:
                # LLMã‹ã‚‰ã®å›ç­”ã‚’å–å¾—
                response = get_llm_response(user_input, expert_choice)
                
                # å›ç­”ã‚’è¡¨ç¤º
                st.subheader("ğŸ’¬ å›ç­”")
                st.info(f"**{expert_choice}ã‹ã‚‰ã®å›ç­”:**")
                st.write(response)
                
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    else:
        st.warning("è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

